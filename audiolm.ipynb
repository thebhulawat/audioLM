{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbZHcxmhN0wrEwmASM3I+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thebhulawat/audioLM/blob/main/audiolm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SrB_Gl6XUZ0",
        "outputId": "4a5297bc-b8bc-43a3-e4bc-f93c6235d5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 17 09:25:34 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiolm-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOVEe0ZMYDQ0",
        "outputId": "c3863699-1076-462c-b5c5-0c9a04103ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiolm-pytorch\n",
            "  Downloading audiolm_pytorch-2.0.7-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.24.0 (from audiolm-pytorch)\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype>=0.16.1 (from audiolm-pytorch)\n",
            "  Downloading beartype-0.18.2-py3-none-any.whl (903 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m903.7/903.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.7.0 (from audiolm-pytorch)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ema-pytorch>=0.2.2 (from audiolm-pytorch)\n",
            "  Downloading ema_pytorch-0.4.5-py3-none-any.whl (8.4 kB)\n",
            "Collecting encodec (from audiolm-pytorch)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fairseq (from audiolm-pytorch)\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from audiolm-pytorch)\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gateloop-transformer>=0.2.3 (from audiolm-pytorch)\n",
            "  Downloading gateloop_transformer-0.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (1.4.0)\n",
            "Collecting local-attention>=1.9.0 (from audiolm-pytorch)\n",
            "  Downloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting pytorch-warmup (from audiolm-pytorch)\n",
            "  Downloading pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (0.1.99)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch) (4.66.2)\n",
            "Collecting vector-quantize-pytorch>=1.12.5 (from audiolm-pytorch)\n",
            "  Downloading vector_quantize_pytorch-1.14.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm-pytorch) (0.4.2)\n",
            "Collecting rotary-embedding-torch (from gateloop-transformer>=0.2.3->audiolm-pytorch)\n",
            "  Downloading rotary_embedding_torch-0.5.3-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm-pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->audiolm-pytorch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting einx[torch]>=0.1.3 (from vector-quantize-pytorch>=1.12.5->audiolm-pytorch)\n",
            "  Downloading einx-0.2.0.tar.gz (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm-pytorch) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm-pytorch) (3.0.10)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->audiolm-pytorch)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->audiolm-pytorch)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm-pytorch) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->audiolm-pytorch)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->audiolm-pytorch)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->audiolm-pytorch) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->audiolm-pytorch) (0.15.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm-pytorch) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->audiolm-pytorch)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->audiolm-pytorch)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->audiolm-pytorch)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->audiolm-pytorch)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm-pytorch) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm-pytorch) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm-pytorch) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->audiolm-pytorch) (1.16.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->vector-quantize-pytorch>=1.12.5->audiolm-pytorch) (2.4.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->audiolm-pytorch)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->audiolm-pytorch)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm-pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm-pytorch) (2024.2.2)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->audiolm-pytorch) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->audiolm-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->audiolm-pytorch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->audiolm-pytorch)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: encodec, fairseq, antlr4-python3-runtime, einx\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45762 sha256=b9b8028b7017746e088dfa7c86cc4699dd05be6875c6378e74f76bee1ab9a776\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291790 sha256=5bc22cb49f1119590cd8f198b6705b61191c2fe416a8e4ec3b3cd7168c6c96aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=6c2675dacf20d890193ceb59615cde3e889ae79c042fe5dd1d2340473c05dfb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for einx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for einx: filename=einx-0.2.0-py3-none-any.whl size=87998 sha256=e7628a3424f9758d675208a2cff669a12cc55f76195937de4b784f5507b2b982\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/4a/44/a5ee7c1b3de3ff83d42be6383107533e069b48a326c6f28fbe\n",
            "Successfully built encodec fairseq antlr4-python3-runtime einx\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, smmap, setproctitle, sentry-sdk, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, docker-pycreds, colorama, beartype, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, gitdb, einx, nvidia-cusolver-cu12, GitPython, wandb, rotary-embedding-torch, pytorch-warmup, local-attention, ema-pytorch, accelerate, vector-quantize-pytorch, gateloop-transformer, fairseq, encodec, audiolm-pytorch\n",
            "Successfully installed GitPython-3.1.43 accelerate-0.29.2 antlr4-python3-runtime-4.8 audiolm-pytorch-2.0.7 beartype-0.18.2 bitarray-2.9.2 colorama-0.4.6 docker-pycreds-0.4.0 einops-0.7.0 einx-0.2.0 ema-pytorch-0.4.5 encodec-0.1.1 fairseq-0.12.2 gateloop-transformer-0.2.4 gitdb-4.0.11 hydra-core-1.0.7 local-attention-1.9.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 pytorch-warmup-0.1.1 rotary-embedding-torch-0.5.3 sacrebleu-2.4.2 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 vector-quantize-pytorch-1.14.7 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import wave\n",
        "import struct\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "from audiolm_pytorch import AudioLM, SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, CoarseTransformer, CoarseTransformerWrapper, FineTransformer, FineTransformerWrapper,  CoarseTransformerTrainer, FineTransformerTrainer\n",
        "from torch import nn\n",
        "import torch\n",
        "import torchaudio\n",
        "dataset_folder = \"dataset\"\n",
        "soundstream_ckpt = \"results/soundstream.8.pt\"\n",
        "hubert_ckpt = 'hubert/hubert_base_ls960.pt'\n",
        "hubert_quantizer = f'hubert/hubert_base_ls960_L9_km500.bin'"
      ],
      "metadata": {
        "id": "w6XCUDOUYZ6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder data generation\n",
        "def get_sinewave(freq=440.0, duration_ms=200, volume=1.0, sample_rate=44100.0):\n",
        "  # code adapted from https://stackoverflow.com/a/33913403\n",
        "  audio = []\n",
        "  num_samples = duration_ms * (sample_rate / 1000.0)\n",
        "  for x in range(int(num_samples)):\n",
        "    audio.append(volume * math.sin(2 * math.pi * freq * (x / sample_rate)))\n",
        "  return audio\n",
        "\n",
        "def save_wav(file_name, audio, sample_rate=44100.0):\n",
        "  # Open up a wav file\n",
        "  wav_file=wave.open(file_name,\"w\")\n",
        "  # wav params\n",
        "  nchannels = 1\n",
        "  sampwidth = 2\n",
        "  # 44100 is the industry standard sample rate - CD quality.  If you need to\n",
        "  # save on file size you can adjust it downwards. The stanard for low quality\n",
        "  # is 8000 or 8kHz.\n",
        "  nframes = len(audio)\n",
        "  comptype = \"NONE\"\n",
        "  compname = \"not compressed\"\n",
        "  wav_file.setparams((nchannels, sampwidth, sample_rate, nframes, comptype, compname))\n",
        "  # WAV files here are using short, 16 bit, signed integers for the\n",
        "  # sample size.  So we multiply the floating point data we have by 32767, the\n",
        "  # maximum value for a short integer.  NOTE: It is theortically possible to\n",
        "  # use the floating point -1.0 to 1.0 data directly in a WAV file but not\n",
        "  # obvious how to do that using the wave module in python.\n",
        "  for sample in audio:\n",
        "      wav_file.writeframes(struct.pack('h', int( sample * 32767.0 )))\n",
        "  wav_file.close()\n",
        "  return\n",
        "\n",
        "def make_placeholder_dataset():\n",
        "  # Make a placeholder dataset with a few .wav files that you can \"train\" on, just to verify things work e2e\n",
        "  if os.path.isdir(dataset_folder):\n",
        "    return\n",
        "  os.makedirs(dataset_folder)\n",
        "  save_wav(f\"{dataset_folder}/example.wav\", get_sinewave())\n",
        "  save_wav(f\"{dataset_folder}/example2.wav\", get_sinewave(duration_ms=500))\n",
        "  os.makedirs(f\"{dataset_folder}/subdirectory\")\n",
        "  save_wav(f\"{dataset_folder}/subdirectory/example.wav\", get_sinewave(freq=330.0))\n",
        "\n",
        "make_placeholder_dataset()\n"
      ],
      "metadata": {
        "id": "ZQQqtiMwZWMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soundstream = SoundStream (\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8\n",
        ")\n",
        "trainer = SoundStreamTrainer(\n",
        "    soundstream,\n",
        "    folder = dataset_folder,\n",
        "    batch_size = 1,\n",
        "    grad_accum_every = 8,\n",
        "    data_max_length = 320 * 32,\n",
        "    save_results_every = 2,\n",
        "    save_model_every = 4,\n",
        "    num_train_steps = 50\n",
        ").cuda()\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f6t7sjGeZrJ",
        "outputId": "11626bdc-7b74-40ec-f4bc-8722c3135883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 56 samples and validating with randomly splitted 3 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) y\n",
            "0: soundstream total loss: 22.605, soundstream recon loss: 0.022 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "0: saving to results\n",
            "0: saving model to results\n",
            "1: soundstream total loss: 26.519, soundstream recon loss: 0.030 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "2: soundstream total loss: 29.534, soundstream recon loss: 0.037 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "2: saving to results\n",
            "3: soundstream total loss: 25.056, soundstream recon loss: 0.029 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "4: soundstream total loss: 19.311, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "4: saving to results\n",
            "4: saving model to results\n",
            "5: soundstream total loss: 26.413, soundstream recon loss: 0.029 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "6: soundstream total loss: 18.220, soundstream recon loss: 0.017 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "6: saving to results\n",
            "7: soundstream total loss: 25.345, soundstream recon loss: 0.024 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "8: soundstream total loss: 23.764, soundstream recon loss: 0.027 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "8: saving to results\n",
            "8: saving model to results\n",
            "9: soundstream total loss: 24.626, soundstream recon loss: 0.028 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "10: soundstream total loss: 21.035, soundstream recon loss: 0.023 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "10: saving to results\n",
            "11: soundstream total loss: 23.168, soundstream recon loss: 0.022 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "12: soundstream total loss: 23.116, soundstream recon loss: 0.027 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "12: saving to results\n",
            "12: saving model to results\n",
            "13: soundstream total loss: 26.005, soundstream recon loss: 0.031 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "14: soundstream total loss: 26.521, soundstream recon loss: 0.033 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "14: saving to results\n",
            "15: soundstream total loss: 18.744, soundstream recon loss: 0.017 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "16: soundstream total loss: 29.321, soundstream recon loss: 0.035 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "16: saving to results\n",
            "16: saving model to results\n",
            "17: soundstream total loss: 26.293, soundstream recon loss: 0.032 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "18: soundstream total loss: 27.041, soundstream recon loss: 0.035 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "18: saving to results\n",
            "19: soundstream total loss: 17.092, soundstream recon loss: 0.015 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "20: soundstream total loss: 20.040, soundstream recon loss: 0.020 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "20: saving to results\n",
            "20: saving model to results\n",
            "21: soundstream total loss: 24.480, soundstream recon loss: 0.028 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "22: soundstream total loss: 35.094, soundstream recon loss: 0.051 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "22: saving to results\n",
            "23: soundstream total loss: 20.560, soundstream recon loss: 0.019 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "24: soundstream total loss: 23.857, soundstream recon loss: 0.026 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "24: saving to results\n",
            "24: saving model to results\n",
            "25: soundstream total loss: 26.625, soundstream recon loss: 0.032 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "26: soundstream total loss: 19.677, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "26: saving to results\n",
            "27: soundstream total loss: 31.515, soundstream recon loss: 0.040 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "28: soundstream total loss: 19.101, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "28: saving to results\n",
            "28: saving model to results\n",
            "29: soundstream total loss: 20.904, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "30: soundstream total loss: 23.738, soundstream recon loss: 0.025 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "30: saving to results\n",
            "31: soundstream total loss: 22.149, soundstream recon loss: 0.023 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "32: soundstream total loss: 21.685, soundstream recon loss: 0.020 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "32: saving to results\n",
            "32: saving model to results\n",
            "33: soundstream total loss: 23.278, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "34: soundstream total loss: 20.652, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "34: saving to results\n",
            "35: soundstream total loss: 20.845, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "36: soundstream total loss: 19.498, soundstream recon loss: 0.019 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "36: saving to results\n",
            "36: saving model to results\n",
            "37: soundstream total loss: 32.644, soundstream recon loss: 0.044 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "38: soundstream total loss: 17.142, soundstream recon loss: 0.015 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "38: saving to results\n",
            "39: soundstream total loss: 22.013, soundstream recon loss: 0.023 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "40: soundstream total loss: 19.020, soundstream recon loss: 0.022 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "40: saving to results\n",
            "40: saving model to results\n",
            "41: soundstream total loss: 19.395, soundstream recon loss: 0.018 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "42: soundstream total loss: 18.227, soundstream recon loss: 0.015 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "42: saving to results\n",
            "43: soundstream total loss: 25.996, soundstream recon loss: 0.030 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "44: soundstream total loss: 28.650, soundstream recon loss: 0.033 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "44: saving to results\n",
            "44: saving model to results\n",
            "45: soundstream total loss: 23.399, soundstream recon loss: 0.026 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "46: soundstream total loss: 25.645, soundstream recon loss: 0.032 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "46: saving to results\n",
            "47: soundstream total loss: 22.971, soundstream recon loss: 0.024 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "48: soundstream total loss: 19.318, soundstream recon loss: 0.021 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "48: saving to results\n",
            "48: saving model to results\n",
            "49: soundstream total loss: 19.692, soundstream recon loss: 0.020 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.000 | discr (scale 0.25) loss: 2.000\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('hubert'):\n",
        "  os.makedirs('hubert')\n",
        "if not os.path.isfile(hubert_ckpt):\n",
        "  hubert_ckpt_download = f\"https://dl.fbaipublicfiles.com/{hubert_ckpt}\"\n",
        "  urllib.request.urlretrieve(hubert_ckpt_download, f\"./{hubert_ckpt}\")\n",
        "if not os.path.isfile(hubert_quantizer):\n",
        "  hubert_quantizer_download =  f\"https://dl.fbaipublicfiles.com/{hubert_quantizer}\"\n",
        "  urllib.request.urlretrieve(hubert_quantizer_download, f\"./{hubert_quantizer}\")\n",
        "\n",
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = f'./{hubert_ckpt}',\n",
        "    kmeans_path = f'./{hubert_quantizer}'\n",
        ")\n",
        "\n",
        "semantic_transformer = SemanticTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    dim = 1024,\n",
        "    depth = 6\n",
        ").cuda()\n",
        "\n",
        "trainer = SemanticTransformerTrainer(\n",
        "    transformer = semantic_transformer,\n",
        "    wav2vec = wav2vec,\n",
        "    folder = dataset_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 50\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icNbhJKBfY6x",
        "outputId": "7ae24316-696c-4073-daba-a7ba6067962a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 56 samples and validating with randomly splitted 3 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) n\n",
            "0: loss: 6.1783528327941895\n",
            "0: valid loss 6.4643874168396\n",
            "0: saving model to results\n",
            "1: loss: 6.646292209625244\n",
            "2: loss: 6.049803733825684\n",
            "3: loss: 6.628210544586182\n",
            "4: loss: 6.395344257354736\n",
            "5: loss: 5.762567520141602\n",
            "6: loss: 5.6280436515808105\n",
            "7: loss: 5.479274272918701\n",
            "8: loss: 5.779816150665283\n",
            "9: loss: 5.933629989624023\n",
            "10: loss: 6.008376121520996\n",
            "11: loss: 5.710422515869141\n",
            "12: loss: 5.516768455505371\n",
            "13: loss: 5.577199935913086\n",
            "14: loss: 5.763340473175049\n",
            "15: loss: 5.511303424835205\n",
            "16: loss: 5.876579761505127\n",
            "17: loss: 5.782003402709961\n",
            "18: loss: 5.3636322021484375\n",
            "19: loss: 4.860294818878174\n",
            "20: loss: 6.998456001281738\n",
            "21: loss: 5.625324249267578\n",
            "22: loss: 5.963174343109131\n",
            "23: loss: 5.231822490692139\n",
            "24: loss: 5.325855255126953\n",
            "25: loss: 5.7134690284729\n",
            "26: loss: 4.7604475021362305\n",
            "27: loss: 5.041004657745361\n",
            "28: loss: 5.738054275512695\n",
            "29: loss: 5.266657829284668\n",
            "30: loss: 6.34613561630249\n",
            "31: loss: 5.241302490234375\n",
            "32: loss: 5.385509014129639\n",
            "33: loss: 5.927690505981445\n",
            "34: loss: 4.206888675689697\n",
            "35: loss: 4.782068252563477\n",
            "36: loss: 5.925504207611084\n",
            "37: loss: 4.972156047821045\n",
            "38: loss: 4.8853254318237305\n",
            "39: loss: 5.226989269256592\n",
            "40: loss: 5.100217342376709\n",
            "41: loss: 4.907782554626465\n",
            "42: loss: 3.4497926235198975\n",
            "43: loss: 4.792606353759766\n",
            "44: loss: 4.712449550628662\n",
            "45: loss: 5.325814247131348\n",
            "46: loss: 5.635377407073975\n",
            "47: loss: 5.079011917114258\n",
            "48: loss: 4.633237838745117\n",
            "49: loss: 2.9775776863098145\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = f'./{hubert_ckpt}',\n",
        "    kmeans_path = f'./{hubert_quantizer}'\n",
        ")\n",
        "\n",
        "soundstream = SoundStream(\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8,\n",
        ")\n",
        "\n",
        "soundstream.load(f'./{soundstream_ckpt}')\n",
        "\n",
        "coarse_transformer = CoarseTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    codebook_size = 1024,\n",
        "    num_coarse_quantizers = 3,\n",
        "    dim = 512,\n",
        "    depth = 6\n",
        ")\n",
        "\n",
        "trainer = CoarseTransformerTrainer(\n",
        "    transformer = coarse_transformer,\n",
        "    codec = soundstream,\n",
        "    wav2vec = wav2vec,\n",
        "    folder = dataset_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 *32,\n",
        "    save_results_every = 2,\n",
        "    save_model_every = 4,\n",
        "    num_train_steps = 50\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8m2PgEmqWXR",
        "outputId": "aa4696fa-52af-42a5-8505-0cf08bdbd668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 56 samples and validating with randomly splitted 3 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) n\n",
            "0: loss: 49.28752517700195\n",
            "0: valid loss 56.12900924682617\n",
            "0: saving model to results\n",
            "1: loss: 50.54399108886719\n",
            "2: loss: 67.16716003417969\n",
            "2: valid loss 58.75642013549805\n",
            "3: loss: 56.899375915527344\n",
            "4: loss: 46.982269287109375\n",
            "4: valid loss 54.066959381103516\n",
            "4: saving model to results\n",
            "5: loss: 43.24955749511719\n",
            "6: loss: 42.151893615722656\n",
            "6: valid loss 35.54770278930664\n",
            "7: loss: 42.31438446044922\n",
            "8: loss: 41.86770248413086\n",
            "8: valid loss 31.354446411132812\n",
            "8: saving model to results\n",
            "9: loss: 17.625350952148438\n",
            "10: loss: 40.83538818359375\n",
            "10: valid loss 27.665346145629883\n",
            "11: loss: 16.7656192779541\n",
            "12: loss: 27.097719192504883\n",
            "12: valid loss 19.532703399658203\n",
            "12: saving model to results\n",
            "13: loss: 26.579416275024414\n",
            "14: loss: 21.958843231201172\n",
            "14: valid loss 23.53536033630371\n",
            "15: loss: 19.677995681762695\n",
            "16: loss: 17.90635871887207\n",
            "16: valid loss 23.024375915527344\n",
            "16: saving model to results\n",
            "17: loss: 14.123507499694824\n",
            "18: loss: 20.433063507080078\n",
            "18: valid loss 17.881948471069336\n",
            "19: loss: 14.530938148498535\n",
            "20: loss: 19.31613540649414\n",
            "20: valid loss 15.826539993286133\n",
            "20: saving model to results\n",
            "21: loss: 11.1070556640625\n",
            "22: loss: 11.550882339477539\n",
            "22: valid loss 14.891934394836426\n",
            "23: loss: 9.740442276000977\n",
            "24: loss: 14.816183090209961\n",
            "24: valid loss 14.327040672302246\n",
            "24: saving model to results\n",
            "25: loss: 14.410967826843262\n",
            "26: loss: 24.55222511291504\n",
            "26: valid loss 16.03251838684082\n",
            "27: loss: 14.172633171081543\n",
            "28: loss: 19.827856063842773\n",
            "28: valid loss 18.771080017089844\n",
            "28: saving model to results\n",
            "29: loss: 20.891698837280273\n",
            "30: loss: 24.996313095092773\n",
            "30: valid loss 17.05571746826172\n",
            "31: loss: 20.988161087036133\n",
            "32: loss: 13.18026065826416\n",
            "32: valid loss 15.455435752868652\n",
            "32: saving model to results\n",
            "33: loss: 12.90954303741455\n",
            "34: loss: 13.559418678283691\n",
            "34: valid loss 7.578643798828125\n",
            "35: loss: 18.241619110107422\n",
            "36: loss: 10.565164566040039\n",
            "36: valid loss 11.586164474487305\n",
            "36: saving model to results\n",
            "37: loss: 14.969882011413574\n",
            "38: loss: 11.78223705291748\n",
            "38: valid loss 12.202874183654785\n",
            "39: loss: 8.832282066345215\n",
            "40: loss: 8.098320960998535\n",
            "40: valid loss 4.451329708099365\n",
            "40: saving model to results\n",
            "41: loss: 11.919005393981934\n",
            "42: loss: 8.979073524475098\n",
            "42: valid loss 13.079886436462402\n",
            "43: loss: 9.788928985595703\n",
            "44: loss: 13.010712623596191\n",
            "44: valid loss 3.036790609359741\n",
            "44: saving model to results\n",
            "45: loss: 12.714876174926758\n",
            "46: loss: 7.360726356506348\n",
            "46: valid loss 8.4152193069458\n",
            "47: loss: 10.592283248901367\n",
            "48: loss: 11.630786895751953\n",
            "48: valid loss 7.0093488693237305\n",
            "48: saving model to results\n",
            "49: loss: 10.366363525390625\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soundstream = SoundStream(\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8,\n",
        ")\n",
        "\n",
        "soundstream.load(f\"./{soundstream_ckpt}\")\n",
        "\n",
        "fine_transformer = FineTransformer(\n",
        "    num_coarse_quantizers = 3,\n",
        "    num_fine_quantizers = 5,\n",
        "    codebook_size = 1024,\n",
        "    dim = 512,\n",
        "    depth = 6\n",
        ")\n",
        "\n",
        "trainer = FineTransformerTrainer(\n",
        "    transformer = fine_transformer,\n",
        "    codec = soundstream,\n",
        "    folder = dataset_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 70\n",
        ")\n",
        "# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
        "# adjusting save_*_every variables for the same reason\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBdcOpPxrNSA",
        "outputId": "32e38816-bda9-4e20-fb8e-5804ea17fa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 56 samples and validating with randomly splitted 3 samples\n",
            "do you want to clear previous experiment checkpoints and results? (y/n) n\n",
            "0: loss: 65.87991333007812\n",
            "0: valid loss 46.00760269165039\n",
            "0: saving model to results\n",
            "1: loss: 53.637046813964844\n",
            "2: loss: 40.55066680908203\n",
            "3: loss: 39.247562408447266\n",
            "4: loss: 36.266170501708984\n",
            "5: loss: 45.16120910644531\n",
            "6: loss: 25.04305648803711\n",
            "7: loss: 14.215118408203125\n",
            "8: loss: 20.674407958984375\n",
            "9: loss: 15.495322227478027\n",
            "10: loss: 17.833988189697266\n",
            "11: loss: 19.73443603515625\n",
            "12: loss: 21.898698806762695\n",
            "13: loss: 16.026182174682617\n",
            "14: loss: 13.337745666503906\n",
            "15: loss: 11.153929710388184\n",
            "16: loss: 14.082469940185547\n",
            "17: loss: 19.795738220214844\n",
            "18: loss: 11.861931800842285\n",
            "19: loss: 14.470977783203125\n",
            "20: loss: 10.093576431274414\n",
            "21: loss: 5.557170867919922\n",
            "22: loss: 13.189838409423828\n",
            "23: loss: 10.095176696777344\n",
            "24: loss: 10.730398178100586\n",
            "25: loss: 10.747623443603516\n",
            "26: loss: 9.027376174926758\n",
            "27: loss: 8.185724258422852\n",
            "28: loss: 7.794223308563232\n",
            "29: loss: 5.819923400878906\n",
            "30: loss: 8.931718826293945\n",
            "31: loss: 10.900712013244629\n",
            "32: loss: 7.78768253326416\n",
            "33: loss: 17.741310119628906\n",
            "34: loss: 12.732431411743164\n",
            "35: loss: 8.447650909423828\n",
            "36: loss: 7.303103446960449\n",
            "37: loss: 8.52487850189209\n",
            "38: loss: 5.945099830627441\n",
            "39: loss: 5.95127534866333\n",
            "40: loss: 4.140234470367432\n",
            "41: loss: 4.049238681793213\n",
            "42: loss: 7.143182754516602\n",
            "43: loss: 7.583034038543701\n",
            "44: loss: 8.122962951660156\n",
            "45: loss: 7.584865570068359\n",
            "46: loss: 5.976302623748779\n",
            "47: loss: 7.188433647155762\n",
            "48: loss: 6.319620132446289\n",
            "49: loss: 8.031679153442383\n",
            "50: loss: 4.3420562744140625\n",
            "51: loss: 7.8777689933776855\n",
            "52: loss: 3.7775869369506836\n",
            "53: loss: 5.626982688903809\n",
            "54: loss: 8.012372970581055\n",
            "55: loss: 3.7231621742248535\n",
            "56: loss: 6.9850263595581055\n",
            "57: loss: 5.9782633781433105\n",
            "58: loss: 11.855131149291992\n",
            "59: loss: 5.986152648925781\n",
            "60: loss: 2.9994261264801025\n",
            "61: loss: 9.977241516113281\n",
            "62: loss: 8.081192016601562\n",
            "63: loss: 9.030138969421387\n",
            "64: loss: 4.935042858123779\n",
            "65: loss: 5.69935417175293\n",
            "66: loss: 3.834944486618042\n",
            "67: loss: 5.095921516418457\n",
            "68: loss: 5.901611804962158\n",
            "69: loss: 3.4620676040649414\n",
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audiolm = AudioLM(\n",
        "    wav2vec = wav2vec,\n",
        "    codec = soundstream,\n",
        "    semantic_transformer = semantic_transformer,\n",
        "    coarse_transformer = coarse_transformer,\n",
        "    fine_transformer = fine_transformer,\n",
        ")\n",
        "generated_wav = audiolm(batch_size = 1)\n",
        "#generate_wav = audiolm(text = ['cirping of birds'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS5NTk24tM6k",
        "outputId": "aa1fda47-161d-46f3-a40c-c1525009d2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating semantic:  57%|█████▋    | 1167/2048 [00:10<00:08, 107.79it/s]\n",
            "generating coarse: 100%|██████████| 512/512 [00:14<00:00, 34.54it/s]\n",
            "generating fine: 100%|██████████| 512/512 [00:34<00:00, 14.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_path = \"out.wav\"\n",
        "sample_rate = 44100\n",
        "torchaudio.save(output_path, generated_wav.cpu(), sample_rate)"
      ],
      "metadata": {
        "id": "impq_b2LtrU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "isERpJzJuXJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}